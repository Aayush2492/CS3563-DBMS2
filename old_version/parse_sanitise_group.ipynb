{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "from html.parser import HTMLParser\n",
    "from html.entities import name2codepoint\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "from rapidfuzz import process, fuzz\n",
    "import threading\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse through source.txt and make a dictionary with key as name and value as number of appearances\n",
    "# The names are unsanitised(containing HTML and Latex symbols).\n",
    "# Similar names are taken distinct here.\n",
    "# After the dictionary is made, the names are written in author_names.txt file\n",
    "\n",
    "# Execution time: 3.3 seconds\n",
    "names = {}\n",
    "with open('source.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if(line[0:2] == '#@'):\n",
    "            line = line.lower()\n",
    "            line_names = line[2:].split(',')\n",
    "            for name in line_names:\n",
    "                name = name.strip()\n",
    "                if name != '' and name[-1] == '\\n':\n",
    "                    name = name[:-1]\n",
    "                name = name.strip()\n",
    "                if name == '':\n",
    "                    continue\n",
    "                if name in names:\n",
    "                    names[name] += 1\n",
    "                else:\n",
    "                    names[name] = 1\n",
    "\n",
    "with open('author_names.txt', 'w') as f:\n",
    "    for key in sorted(names.keys()):\n",
    "        f.write(key+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution time: 184 seconds\n",
    "\n",
    "# Sanitises the names present in the above generated author_names.txt file.\n",
    "#\n",
    "# ...............Write more info..................\n",
    "#\n",
    "# Creates a dictionary with key as sanitised_name and value as number of appearances.\n",
    "# Writes the sanitised names in author_names_sanitised.txt file\n",
    "\n",
    "# Very slow. One solution searching for \\,$ gave like 30 results. So sanitise them only\n",
    "sanitised_names = {}\n",
    "\n",
    "def raw_string_c_(og_name):\n",
    "    modified_name = og_name\n",
    "    modified_name = modified_name.replace('\\W', 'W')\n",
    "    # modified_name = modified_name.replace(\"\\''a\", \"\\\\\\'a\")\n",
    "    modified_name = modified_name.replace(\"\\a\", \"\\\\a\")\n",
    "    modified_name = modified_name.replace(\"\\v\", \"\\\\v\")\n",
    "    modified_name = modified_name.replace(\"\\b\", \"\\\\b\")\n",
    "    modified_name = modified_name.replace(\"\\\"\", '\\\\\"')\n",
    "    modified_name = modified_name.replace(\"\\''\", '\\\\\\'')\n",
    "    return modified_name\n",
    "\n",
    "def name_corrector(og_name):\n",
    "    name_modified1 = og_name\n",
    "    name_modified2 = raw_string_c_(og_name)\n",
    "    name_modified1 = name_modified1.lower()\n",
    "    name_modified1 = html.unescape(name_modified1)\n",
    "    name_modified2 = LatexNodes2Text().latex_to_text(name_modified2)\n",
    "    if len(name_modified1) == len(name_modified2):\n",
    "        final_name = og_name\n",
    "    elif len(name_modified1) > len(name_modified2):\n",
    "        final_name = name_modified2\n",
    "    else:\n",
    "        final_name = name_modified1\n",
    "    return final_name\n",
    "\n",
    "for key in names:\n",
    "    sanitised_names[key] = name_corrector(key)\n",
    "\n",
    "sorted_sanitised_names = sorted(list(sanitised_names.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(sanitised_names) == len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\"': 3,\n",
      " '&': 11,\n",
      " \"'\": 2,\n",
      " '(': 4,\n",
      " '.': 16,\n",
      " '0': 3,\n",
      " '1': 2,\n",
      " '2': 2,\n",
      " '3': 1,\n",
      " '?': 1,\n",
      " '_': 1,\n",
      " '`': 1,\n",
      " 'a': 45609,\n",
      " 'b': 19813,\n",
      " 'c': 32069,\n",
      " 'd': 33980,\n",
      " 'e': 17535,\n",
      " 'f': 14813,\n",
      " 'g': 23889,\n",
      " 'h': 24248,\n",
      " 'i': 8526,\n",
      " 'j': 61027,\n",
      " 'k': 23683,\n",
      " 'l': 20898,\n",
      " 'm': 56300,\n",
      " 'n': 13545,\n",
      " 'o': 4743,\n",
      " 'p': 27264,\n",
      " 'q': 1841,\n",
      " 'r': 36822,\n",
      " 's': 45204,\n",
      " 't': 24452,\n",
      " 'u': 2389,\n",
      " 'v': 10113,\n",
      " 'w': 15562,\n",
      " 'x': 5368,\n",
      " 'y': 15585,\n",
      " 'z': 6456,\n",
      " '\\x8a': 1,\n",
      " 'à': 10,\n",
      " 'á': 147,\n",
      " 'â': 2,\n",
      " 'ä': 1,\n",
      " 'å': 24,\n",
      " 'æ': 1,\n",
      " 'ç': 15,\n",
      " 'è': 2,\n",
      " 'é': 84,\n",
      " 'ê': 1,\n",
      " 'ì': 1,\n",
      " 'í': 19,\n",
      " 'ï': 2,\n",
      " 'ò': 2,\n",
      " 'ó': 22,\n",
      " 'ö': 91,\n",
      " 'ø': 37,\n",
      " 'ú': 1,\n",
      " 'ü': 12,\n",
      " 'ć': 1,\n",
      " 'č': 4,\n",
      " 'ī': 1,\n",
      " 'ľ': 1,\n",
      " 'ł': 26,\n",
      " 'ş': 25,\n",
      " 'š': 24,\n",
      " 'ž': 11}\n"
     ]
    }
   ],
   "source": [
    "s = {}\n",
    "for key in sorted_sanitised_names:\n",
    "    if len(key) == 0:\n",
    "        print('Here') # It never reached here. No key is empty in sanitised_names.\n",
    "        continue\n",
    "    if key[0] in s:\n",
    "        s[key[0]] += 1\n",
    "    else:\n",
    "        s[key[0]] = 1\n",
    "\n",
    "pprint.pprint(s)\n",
    "\n",
    "sum1 = 0\n",
    "for key in sorted(s.keys()):\n",
    "    if key <= 'a':\n",
    "        sum1 += s[key]\n",
    "\n",
    "sum2 = 0\n",
    "for key in sorted(s.keys()):\n",
    "    if key >= 'z':\n",
    "        sum2 += s[key]\n",
    "\n",
    "lengths = []\n",
    "for i in range(1,27):\n",
    "    if i == 1:\n",
    "        lengths.append(sum1)\n",
    "    elif i == 26:\n",
    "        lengths.append(sum2)\n",
    "    else:\n",
    "        lengths.append(s[chr(i+96)])\n",
    "lengths.insert(0, 0)\n",
    "cu_lengths = [sum(lengths[0:x+1]) for x in range(0, len(lengths)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 45656, 19813, 32069, 33980, 17535, 14813, 23889, 24248, 8526, 61027, 23683, 20898, 56300, 13545, 4743, 27264, 1841, 36822, 45204, 24452, 2389, 10113, 15562, 5368, 15585, 7024]\n",
      "[0, 45656, 65469, 97538, 131518, 149053, 163866, 187755, 212003, 220529, 281556, 305239, 326137, 382437, 395982, 400725, 427989, 429830, 466652, 511856, 536308, 538697, 548810, 564372, 569740, 585325, 592349, 592349]\n"
     ]
    }
   ],
   "source": [
    "print(lengths)\n",
    "print(cu_lengths)\n",
    "assert(sum(lengths) == len(sanitised_names)) # character division is proper\n",
    "assert(cu_lengths[-1] == len(sanitised_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will group the names according to their similarity in fuzzy matching(95 percent threshold chosen).\n",
    "# group_names dictionary has key as the name and value as a list of names that are similar to it as values\n",
    "\n",
    "count = 0\n",
    "lock = threading.Lock() \n",
    "name_dicts = [None]*26\n",
    "for i in range(0, 26):\n",
    "    name_dicts[i] = {'grouped_names': {}}\n",
    "''' Takes indices of keys of sanitised_names, groups them according to their similarity and writes them in\n",
    "grouped_names dictionary.\n",
    "'''\n",
    "def group_names(thread_id, start_idx, end_idx):\n",
    "    global count\n",
    "    for idx in range(start_idx, end_idx+1):\n",
    "        key = sorted_sanitised_names[idx]\n",
    "        if len(name_dicts[thread_id]['grouped_names']) == 0:\n",
    "            name_dicts[thread_id]['grouped_names'][key] = []\n",
    "            continue\n",
    "        match = process.extractOne(key, name_dicts[thread_id]['grouped_names'].keys(), scorer=fuzz.token_sort_ratio)\n",
    "        if match[1] > 90:\n",
    "            name_dicts[thread_id]['grouped_names'][match[0]].append(key)\n",
    "        else:\n",
    "            name_dicts[thread_id]['grouped_names'][key] = []\n",
    "        lock.acquire()\n",
    "        count+=1\n",
    "        if count % 3000 == 0:\n",
    "            print(f\"Grouping progress: {count/len(names)*100.0}% done. Total: {len(names)}, Remaining: {len(names)-count}\")\n",
    "        lock.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping progress: 0.5064581859680695% done. Total: 592349, Remaining: 589349\n",
      "Grouping progress: 1.012916371936139% done. Total: 592349, Remaining: 586349\n",
      "Grouping progress: 1.5193745579042084% done. Total: 592349, Remaining: 583349\n",
      "Grouping progress: 2.025832743872278% done. Total: 592349, Remaining: 580349\n",
      "Grouping progress: 2.5322909298403475% done. Total: 592349, Remaining: 577349\n",
      "Grouping progress: 3.038749115808417% done. Total: 592349, Remaining: 574349\n",
      "Grouping progress: 3.5452073017764865% done. Total: 592349, Remaining: 571349\n",
      "Grouping progress: 4.051665487744556% done. Total: 592349, Remaining: 568349\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/aayush/Desktop/AAYUSH/COLLEGE/SEMESTERS/SEMESTER 4/CS3563/Assignments/Assignments 2/code.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aayush/Desktop/AAYUSH/COLLEGE/SEMESTERS/SEMESTER%204/CS3563/Assignments/Assignments%202/code.ipynb#ch0000007?line=6'>7</a>\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aayush/Desktop/AAYUSH/COLLEGE/SEMESTERS/SEMESTER%204/CS3563/Assignments/Assignments%202/code.ipynb#ch0000007?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m thread \u001b[39min\u001b[39;00m threads:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aayush/Desktop/AAYUSH/COLLEGE/SEMESTERS/SEMESTER%204/CS3563/Assignments/Assignments%202/code.ipynb#ch0000007?line=9'>10</a>\u001b[0m     thread\u001b[39m.\u001b[39mjoin()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aayush/Desktop/AAYUSH/COLLEGE/SEMESTERS/SEMESTER%204/CS3563/Assignments/Assignments%202/code.ipynb#ch0000007?line=11'>12</a>\u001b[0m count2 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aayush/Desktop/AAYUSH/COLLEGE/SEMESTERS/SEMESTER%204/CS3563/Assignments/Assignments%202/code.ipynb#ch0000007?line=12'>13</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauthor_names_grouped.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:1053\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1049'>1050</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1051'>1052</a>\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1052'>1053</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1053'>1054</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1054'>1055</a>\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1055'>1056</a>\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1056'>1057</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:1073\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1069'>1070</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1071'>1072</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1072'>1073</a>\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1073'>1074</a>\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   <a href='file:///opt/homebrew/Cellar/python%403.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py?line=1074'>1075</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping progress: 4.558123673712625% done. Total: 592349, Remaining: 565349\n",
      "Grouping progress: 5.064581859680695% done. Total: 592349, Remaining: 562349\n",
      "Grouping progress: 5.571040045648765% done. Total: 592349, Remaining: 559349\n",
      "Grouping progress: 6.077498231616834% done. Total: 592349, Remaining: 556349\n",
      "Grouping progress: 6.583956417584903% done. Total: 592349, Remaining: 553349\n",
      "Grouping progress: 7.090414603552973% done. Total: 592349, Remaining: 550349\n",
      "Grouping progress: 7.596872789521042% done. Total: 592349, Remaining: 547349\n",
      "Grouping progress: 8.103330975489111% done. Total: 592349, Remaining: 544349\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "threads = []\n",
    "for i in range(0,26):\n",
    "    threads.append(threading.Thread(target=group_names, args=(i, cu_lengths[i], cu_lengths[i+1]-1)))\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "count2 = 0\n",
    "with open(f'author_names_grouped.txt', 'w') as f:\n",
    "    for i in range(0,26):\n",
    "        for key in  name_dicts[i]['grouped_names'].keys():\n",
    "            f.write(f\"{count2}% {key}\\n\") # using % because its not present in author_names_grouped.txt\n",
    "            for name in name_dicts[i]['grouped_names'][key]:\n",
    "                f.write(f\"{count2}% {name}\\n\")\n",
    "            count2+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitised_to_id = {}\n",
    "with open('author_names_grouped.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line[0:-1]\n",
    "        a = line.split('% ')\n",
    "        # if(a[1] == \"carlos d'andrea\"):\n",
    "        #     print(\"Here2\")\n",
    "        if a[1] in sanitised_to_id:\n",
    "            print('Here')\n",
    "            print(a[1])\n",
    "        sanitised_to_id[a[1]] = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592349 592349\n"
     ]
    }
   ],
   "source": [
    "print(len(sanitised_to_id), len(sanitised_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "extras = {}\n",
    "sentinel = 600000\n",
    "check1 = 0\n",
    "check2 = 0\n",
    "with open('source.txt', 'r') as f1, open('source_clean.txt', 'w') as f2:\n",
    "    for line in f1:\n",
    "        # line = line.strip()\n",
    "        if(line[0:2] == '#@'):\n",
    "            if line[0:-1] == \"#@\": # This is the case when paper has no author.\n",
    "                f2.write(line)\n",
    "                continue\n",
    "            line = line.lower()\n",
    "            line_names = line[2:].split(',')\n",
    "            f2.write('#@')\n",
    "            for name in line_names:\n",
    "                name = name.strip()\n",
    "                if name != '' and name[-1] == '\\n':\n",
    "                    name = name[:-1]\n",
    "                name = name.strip()\n",
    "                if name == '':\n",
    "                    continue\n",
    "                if name in sanitised_names.keys():\n",
    "                    if sanitised_names[name] in sanitised_to_id.keys():\n",
    "                        f2.write(f\"{sanitised_to_id[sanitised_names[name]]},\")\n",
    "                    else:\n",
    "                        # print('Here')\n",
    "                        check1+=1\n",
    "                        # print(f\"{sanitised_names[name]}\")\n",
    "                        extras[sanitised_names[name]] = sentinel\n",
    "                        f2.write(f\"{sentinel},\")\n",
    "                        sentinel+=1\n",
    "                else:\n",
    "                    # print('Here')\n",
    "                    check2+=1\n",
    "            f2.write('\\n')\n",
    "        else:\n",
    "            f2.write(line)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571 0\n"
     ]
    }
   ],
   "source": [
    "print(check1, check2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if replacements to source_clean are error free or not by asserting authors replaced by integers\n",
    "with open('source_clean.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if(line[0:2] == '#@'):\n",
    "            if line[0:-1] == \"#@\": # This is the case when paper has no author.\n",
    "                continue\n",
    "            line = line[0:-1]\n",
    "            line_numbers = line[2:].split(',')\n",
    "            for number in line_numbers:\n",
    "                number = number.strip()\n",
    "                if number == '':\n",
    "                    continue\n",
    "                if(not number.isnumeric()):\n",
    "                    print(f\"{number} is not a number\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extras.txt', 'w') as f:\n",
    "    for key in extras.keys():\n",
    "        f.write(f\"{extras[key]}% {key}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35eeb062e26c9701e83ea6659403bee76c3934b635ee6a9209e92f796c1714bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('EE5606_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
